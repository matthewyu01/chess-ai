{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f89e368b908d1a3af1a9cb902a14ad307df42a403bd95d8c2513650abfe81cff"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    \"\"\"Chess Positions Evaluation Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        position = np.array(self.df.iloc[idx, :-1])\n",
    "        eval_ = np.array(self.df.iloc[idx, -1]/100)\n",
    "        \n",
    "        sample = {'position': torch.from_numpy(position), 'eval': torch.from_numpy(eval_)}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChessDataset(csv_file='data/stockfish_depth0e.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "        self.fc1 = nn.Linear(513, 64)\n",
    "        # self.conv1 = nn.Conv1d(64, 8, 3) #input, output channels, kernel_size\n",
    "        # self.conv2 = nn.Conv2d(8, 8, 3)\n",
    "        # self.conv3 = nn.Conv2d(8, 8, 3)\n",
    "        # self.conv4 = nn.Conv2d(8, 8, 3)\n",
    "        self.fc2 = nn.Linear(64, 32) \n",
    "        self.fc3 = nn.Linear(32,8)\n",
    "        self.fc4 = nn.Linear(8, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = self.conv1(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = self.conv4(x)   \n",
    "        x = torch.reshape(x, (-1,)) # flattens into 1d tensor\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(F.relu(x))\n",
    "        x = self.fc4(torch.sigmoid(x))\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "net = Net()#.cuda()\n",
    "\n",
    "# Load model\n",
    "net.load_state_dict(torch.load('chess_ai0.pt'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1., -1.], [1., -1.]])\n",
    "t = t.cuda()\n",
    "t.get_device()"
   ]
  },
  {
   "source": [
    "# TRAINING DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, batch_size=1,\n",
    "                        shuffle=True, num_workers=0) \n",
    "#num_workers = 0 doesn't use GPU. GPU seems to be a lot slower than CPU,.\n",
    "#data set is prob too big or my laptop nvidia GPU is just trash\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0009) #lr = 0.001\n",
    "criterion = nn.MSELoss() \n",
    "\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['position'].reshape(1, 513).float()#.cuda()\n",
    "        labels = data['eval'].float()#.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 400 == 399:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 400))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_eval():\n",
    "    board = generate_rand_board()\n",
    "    #print(convert_board(board))\n",
    "    torch_board = torch.from_numpy(convert_board(board).reshape(1, 513)).float()\n",
    "    net_eval = net(torch_board)\n",
    "    sf_eval = stockfish_evaluation(board)\n",
    "    print(f\"NN: {net_eval} Stockfish: {sf_eval/100}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NN: tensor([0.8682], grad_fn=<AddBackward0>) Stockfish: 2.09\nNN: tensor([2.4021], grad_fn=<AddBackward0>) Stockfish: 0.99\nNN: tensor([-0.5156], grad_fn=<AddBackward0>) Stockfish: 5.47\nNN: tensor([6.3615], grad_fn=<AddBackward0>) Stockfish: 18.01\nNN: tensor([7.0650], grad_fn=<AddBackward0>) Stockfish: 10.78\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    compare_eval()"
   ]
  },
  {
   "source": [
    "# Choosing Best Move with Minimax"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_prediction(position: chess.Board):\n",
    "    board_rep = convert_board(position)\n",
    "    torch_board = torch.from_numpy(board_rep.reshape(1, 513)).float()\n",
    "    return net(torch_board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "def minimax(position: chess.Board, maximizing_player, depth: int = 5): # alpha: int = -1e9, beta: int = 1e9 \n",
    "    \"\"\"\n",
    "    Minimax with alpha-beta pruning to save time\n",
    "    \"\"\"\n",
    "    #just used minimax from connectx kaggle agent\n",
    "\n",
    "    alpha = -1000 #could be -np.Inf\n",
    "    beta = 1000\n",
    "    if depth == 0 or position.is_game_over():\n",
    "        return nn_prediction(position)\n",
    "\n",
    "    if maximizing_player:\n",
    "        value = -np.Inf\n",
    "        for move in position.legal_moves:\n",
    "            pos_copy = position.copy()\n",
    "            if not position.remove_piece_at(move.from_square).color == chess.BLACK:\n",
    "                position = pos_copy.copy()\n",
    "                continue\n",
    "            position.push(move)\n",
    "            eval_tensor = minimax(position, False, depth - 1)\n",
    "            if torch_eval > value:\n",
    "                value = eval_tensor\n",
    "            position.pop()\n",
    "            alpha = max(alpha, value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return value\n",
    "\n",
    "    else:\n",
    "        value = np.Inf\n",
    "        for move in position.legal_moves:\n",
    "            pos_copy = position.copy()\n",
    "            if position.remove_piece_at(move.from_square).color == chess.WHITE:\n",
    "                position = pos_copy.copy()\n",
    "                continue\n",
    "            position.push(move)\n",
    "            value = min(value, minimax(position, True, depth - 1))\n",
    "            position.pop()\n",
    "            beta = min(beta, value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_move(position: chess.Board, depth: int = 0):\n",
    "    best_evaluation = -1000\n",
    "    best_move = None\n",
    "    for move in position.legal_moves:\n",
    "        if best_move == None:\n",
    "            best_move = move\n",
    "        \n",
    "        #print(move)\n",
    "        value = -1000\n",
    "\n",
    "        # pos_copy = position.copy()\n",
    "        # if position.remove_piece_at(move.from_square).color == chess.WHITE:\n",
    "        #         position = pos_copy.copy()\n",
    "        #         continue\n",
    "        position.push(move)\n",
    "        value = nn_prediction(position)\n",
    "        if depth > 0:\n",
    "            if position.turn == chess.WHITE:\n",
    "                value = minimax(position, False, depth - 1) \n",
    "        print(move,value)\n",
    "        position.pop()\n",
    "        if value > best_evaluation:\n",
    "            best_evaluation = value\n",
    "            best_move = move\n",
    "    return best_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game():\n",
    "    board = chess.Board()\n",
    "    board.push_san(\"e4\")\n",
    "    board.push_san(\"e5\")    \n",
    "    while not board.is_game_over():   \n",
    "        nn_move = find_best_move(board,24) #depth is working ?\n",
    "        board.push(nn_move)\n",
    "        print(board)\n",
    "        print(nn_move)\n",
    "        moved = False\n",
    "        while not moved:\n",
    "            try:\n",
    "                sqr = input('your move')\n",
    "                if sqr == 'q' or sqr == 'quit':\n",
    "                    return\n",
    "                if sqr[0] == 'n':\n",
    "                    sqr = 'N' + sqr[1:]\n",
    "                board.push_san(sqr)\n",
    "                moved = True\n",
    "            except:\n",
    "                moved = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Backward0>)\n",
      "e7h7 tensor([-2.1566], grad_fn=<AddBackward0>)\n",
      "e7g7 tensor([0.4514], grad_fn=<AddBackward0>)\n",
      "e7f7 tensor([1.1550], grad_fn=<AddBackward0>)\n",
      "e7d7 tensor([-4.2814], grad_fn=<AddBackward0>)\n",
      "e7c7 tensor([-3.8046], grad_fn=<AddBackward0>)\n",
      "e7b7 tensor([-2.4133], grad_fn=<AddBackward0>)\n",
      "e7a7 tensor([2.4528], grad_fn=<AddBackward0>)\n",
      "e7e6 tensor([2.6326], grad_fn=<AddBackward0>)\n",
      "e7e5 tensor([2.0135], grad_fn=<AddBackward0>)\n",
      "e7e4 tensor([2.0401], grad_fn=<AddBackward0>)\n",
      "e7e3 tensor([5.1969], grad_fn=<AddBackward0>)\n",
      "e7e2 tensor([-0.5165], grad_fn=<AddBackward0>)\n",
      "e7e1 tensor([-0.8018], grad_fn=<AddBackward0>)\n",
      "d2e3 tensor([2.5440], grad_fn=<AddBackward0>)\n",
      "d2d3 tensor([4.4889], grad_fn=<AddBackward0>)\n",
      "d2c3 tensor([4.6439], grad_fn=<AddBackward0>)\n",
      "d2e1 tensor([4.2172], grad_fn=<AddBackward0>)\n",
      "d2d1 tensor([2.4185], grad_fn=<AddBackward0>)\n",
      "d2c1 tensor([-0.2841], grad_fn=<AddBackward0>)\n",
      "a1a8 tensor([2.0502], grad_fn=<AddBackward0>)\n",
      "a1a7 tensor([2.4885], grad_fn=<AddBackward0>)\n",
      "a1a6 tensor([1.0905], grad_fn=<AddBackward0>)\n",
      "a1a5 tensor([0.7936], grad_fn=<AddBackward0>)\n",
      "a1a4 tensor([0.0093], grad_fn=<AddBackward0>)\n",
      "a1a3 tensor([5.0918], grad_fn=<AddBackward0>)\n",
      "a1a2 tensor([1.6968], grad_fn=<AddBackward0>)\n",
      "a1h1 tensor([3.1843], grad_fn=<AddBackward0>)\n",
      "a1g1 tensor([1.7081], grad_fn=<AddBackward0>)\n",
      "a1f1 tensor([-0.0530], grad_fn=<AddBackward0>)\n",
      "a1e1 tensor([3.0314], grad_fn=<AddBackward0>)\n",
      "a1d1 tensor([0.7622], grad_fn=<AddBackward0>)\n",
      "a1c1 tensor([3.1551], grad_fn=<AddBackward0>)\n",
      "a1b1 tensor([2.9505], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([5.6225], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([4.3568], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([5.3010], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([5.2895], grad_fn=<AddBackward0>)\n",
      ". . . . R . . .\n",
      ". . . . . . . .\n",
      ". . p k . . . .\n",
      ". . . p . . . p\n",
      ". P . n . . . .\n",
      ". . . . . . P .\n",
      ". . . K . P . .\n",
      "R . . . . . . .\n",
      "e7e8\n",
      "e8h8 tensor([13.2988], grad_fn=<AddBackward0>)\n",
      "e8g8 tensor([11.3233], grad_fn=<AddBackward0>)\n",
      "e8f8 tensor([14.3426], grad_fn=<AddBackward0>)\n",
      "e8d8 tensor([10.0273], grad_fn=<AddBackward0>)\n",
      "e8c8 tensor([8.3305], grad_fn=<AddBackward0>)\n",
      "e8b8 tensor([10.1554], grad_fn=<AddBackward0>)\n",
      "e8a8 tensor([14.6408], grad_fn=<AddBackward0>)\n",
      "e8e7 tensor([10.1632], grad_fn=<AddBackward0>)\n",
      "e8e6 tensor([16.1154], grad_fn=<AddBackward0>)\n",
      "d2e3 tensor([6.4372], grad_fn=<AddBackward0>)\n",
      "d2d3 tensor([6.3413], grad_fn=<AddBackward0>)\n",
      "d2c3 tensor([6.6084], grad_fn=<AddBackward0>)\n",
      "d2e2 tensor([7.6802], grad_fn=<AddBackward0>)\n",
      "d2c2 tensor([7.5602], grad_fn=<AddBackward0>)\n",
      "d2e1 tensor([5.8619], grad_fn=<AddBackward0>)\n",
      "d2d1 tensor([3.6332], grad_fn=<AddBackward0>)\n",
      "d2c1 tensor([0.9077], grad_fn=<AddBackward0>)\n",
      "a1a8 tensor([3.4082], grad_fn=<AddBackward0>)\n",
      "a1a7 tensor([7.5158], grad_fn=<AddBackward0>)\n",
      "a1a6 tensor([2.2124], grad_fn=<AddBackward0>)\n",
      "a1a5 tensor([1.9363], grad_fn=<AddBackward0>)\n",
      "a1a4 tensor([1.1921], grad_fn=<AddBackward0>)\n",
      "a1a3 tensor([7.1450], grad_fn=<AddBackward0>)\n",
      "a1a2 tensor([2.8622], grad_fn=<AddBackward0>)\n",
      "a1h1 tensor([4.4940], grad_fn=<AddBackward0>)\n",
      "a1g1 tensor([3.3641], grad_fn=<AddBackward0>)\n",
      "a1f1 tensor([1.2744], grad_fn=<AddBackward0>)\n",
      "a1e1 tensor([3.7711], grad_fn=<AddBackward0>)\n",
      "a1d1 tensor([2.4679], grad_fn=<AddBackward0>)\n",
      "a1c1 tensor([4.5122], grad_fn=<AddBackward0>)\n",
      "a1b1 tensor([4.7321], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([7.6679], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([5.7734], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([7.3211], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([7.1930], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . p k R . . .\n",
      ". . . p . . . p\n",
      ". P . . . . . .\n",
      ". . . . . . P .\n",
      ". . . K . P . .\n",
      "R . . . . . . .\n",
      "e8e6\n",
      "d2e3 tensor([13.4790], grad_fn=<AddBackward0>)\n",
      "d2d3 tensor([13.5890], grad_fn=<AddBackward0>)\n",
      "d2c3 tensor([13.7891], grad_fn=<AddBackward0>)\n",
      "d2e2 tensor([13.8171], grad_fn=<AddBackward0>)\n",
      "d2c2 tensor([14.3890], grad_fn=<AddBackward0>)\n",
      "d2e1 tensor([12.6903], grad_fn=<AddBackward0>)\n",
      "d2d1 tensor([11.4855], grad_fn=<AddBackward0>)\n",
      "d2c1 tensor([6.5248], grad_fn=<AddBackward0>)\n",
      "a1a8 tensor([12.9418], grad_fn=<AddBackward0>)\n",
      "a1a7 tensor([14.3708], grad_fn=<AddBackward0>)\n",
      "a1a6 tensor([8.1988], grad_fn=<AddBackward0>)\n",
      "a1a5 tensor([8.3940], grad_fn=<AddBackward0>)\n",
      "a1a4 tensor([6.1379], grad_fn=<AddBackward0>)\n",
      "a1a3 tensor([14.4252], grad_fn=<AddBackward0>)\n",
      "a1a2 tensor([9.6712], grad_fn=<AddBackward0>)\n",
      "a1h1 tensor([10.2661], grad_fn=<AddBackward0>)\n",
      "a1g1 tensor([8.3686], grad_fn=<AddBackward0>)\n",
      "a1f1 tensor([5.6136], grad_fn=<AddBackward0>)\n",
      "a1e1 tensor([8.6398], grad_fn=<AddBackward0>)\n",
      "a1d1 tensor([6.5730], grad_fn=<AddBackward0>)\n",
      "a1c1 tensor([9.1557], grad_fn=<AddBackward0>)\n",
      "a1b1 tensor([8.8034], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([14.0557], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([12.2451], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([13.6973], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([13.7525], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . p . k . . .\n",
      ". . . p . . . p\n",
      ". P . . . . . .\n",
      "R . . . . . P .\n",
      ". . . K . P . .\n",
      ". . . . . . . .\n",
      "a1a3\n",
      "a3a8 tensor([13.4468], grad_fn=<AddBackward0>)\n",
      "a3a7 tensor([14.6212], grad_fn=<AddBackward0>)\n",
      "a3a6 tensor([9.1659], grad_fn=<AddBackward0>)\n",
      "a3a5 tensor([12.5118], grad_fn=<AddBackward0>)\n",
      "a3a4 tensor([6.8741], grad_fn=<AddBackward0>)\n",
      "a3f3 tensor([13.2872], grad_fn=<AddBackward0>)\n",
      "a3e3 tensor([12.1984], grad_fn=<AddBackward0>)\n",
      "a3d3 tensor([8.8352], grad_fn=<AddBackward0>)\n",
      "a3c3 tensor([7.3892], grad_fn=<AddBackward0>)\n",
      "a3b3 tensor([9.9358], grad_fn=<AddBackward0>)\n",
      "a3a2 tensor([10.5919], grad_fn=<AddBackward0>)\n",
      "a3a1 tensor([14.5729], grad_fn=<AddBackward0>)\n",
      "d2d3 tensor([10.0907], grad_fn=<AddBackward0>)\n",
      "d2e2 tensor([14.4873], grad_fn=<AddBackward0>)\n",
      "d2c2 tensor([14.7562], grad_fn=<AddBackward0>)\n",
      "d2e1 tensor([15.0150], grad_fn=<AddBackward0>)\n",
      "d2d1 tensor([14.8304], grad_fn=<AddBackward0>)\n",
      "d2c1 tensor([13.2460], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([14.6247], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([14.1698], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([13.4431], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([14.3987], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . p . k . . .\n",
      ". . . . . . . p\n",
      ". P . p . . . .\n",
      "R . . . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "d2e1\n",
      "a3a8 tensor([14.4544], grad_fn=<AddBackward0>)\n",
      "a3a7 tensor([15.2293], grad_fn=<AddBackward0>)\n",
      "a3a6 tensor([11.1992], grad_fn=<AddBackward0>)\n",
      "a3a5 tensor([13.8023], grad_fn=<AddBackward0>)\n",
      "a3a4 tensor([8.9556], grad_fn=<AddBackward0>)\n",
      "a3f3 tensor([12.0915], grad_fn=<AddBackward0>)\n",
      "a3e3 tensor([14.6361], grad_fn=<AddBackward0>)\n",
      "a3d3 tensor([11.5319], grad_fn=<AddBackward0>)\n",
      "a3c3 tensor([9.2416], grad_fn=<AddBackward0>)\n",
      "a3b3 tensor([11.6720], grad_fn=<AddBackward0>)\n",
      "a3a2 tensor([14.4875], grad_fn=<AddBackward0>)\n",
      "a3a1 tensor([13.6958], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([14.7309], grad_fn=<AddBackward0>)\n",
      "e1d2 tensor([14.9161], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([15.0194], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([15.0170], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([15.1150], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([14.8168], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([14.2822], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([14.9613], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      ". . p . . k . .\n",
      ". . . . . . . p\n",
      ". P . p . . . .\n",
      ". . . . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "a3a7\n",
      "a7a8 tensor([14.1576], grad_fn=<AddBackward0>)\n",
      "a7h7 tensor([8.7097], grad_fn=<AddBackward0>)\n",
      "a7g7 tensor([13.1541], grad_fn=<AddBackward0>)\n",
      "a7f7 tensor([13.7429], grad_fn=<AddBackward0>)\n",
      "a7e7 tensor([6.6350], grad_fn=<AddBackward0>)\n",
      "a7d7 tensor([5.6323], grad_fn=<AddBackward0>)\n",
      "a7c7 tensor([3.1156], grad_fn=<AddBackward0>)\n",
      "a7b7 tensor([8.4620], grad_fn=<AddBackward0>)\n",
      "a7a6 tensor([10.5893], grad_fn=<AddBackward0>)\n",
      "a7a5 tensor([13.4103], grad_fn=<AddBackward0>)\n",
      "a7a4 tensor([8.2970], grad_fn=<AddBackward0>)\n",
      "a7a3 tensor([15.0150], grad_fn=<AddBackward0>)\n",
      "a7a2 tensor([14.2091], grad_fn=<AddBackward0>)\n",
      "a7a1 tensor([13.3144], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([14.4327], grad_fn=<AddBackward0>)\n",
      "e1d2 tensor([14.6212], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([14.8341], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([14.7714], grad_fn=<AddBackward0>)\n",
      "b4b5 tensor([15.0261], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([13.9342], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([14.7994], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([14.8237], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      ". . p . k . . .\n",
      ". P . . . . . p\n",
      ". . . p . . . .\n",
      ". . . . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "b4b5\n",
      "a7a8 tensor([13.9767], grad_fn=<AddBackward0>)\n",
      "a7h7 tensor([8.1870], grad_fn=<AddBackward0>)\n",
      "a7g7 tensor([12.8933], grad_fn=<AddBackward0>)\n",
      "a7f7 tensor([13.5272], grad_fn=<AddBackward0>)\n",
      "a7e7 tensor([6.1684], grad_fn=<AddBackward0>)\n",
      "a7d7 tensor([5.2348], grad_fn=<AddBackward0>)\n",
      "a7c7 tensor([3.7803], grad_fn=<AddBackward0>)\n",
      "a7b7 tensor([5.3436], grad_fn=<AddBackward0>)\n",
      "a7a6 tensor([11.4428], grad_fn=<AddBackward0>)\n",
      "a7a5 tensor([8.3300], grad_fn=<AddBackward0>)\n",
      "a7a4 tensor([9.9106], grad_fn=<AddBackward0>)\n",
      "a7a3 tensor([14.9205], grad_fn=<AddBackward0>)\n",
      "a7a2 tensor([14.0441], grad_fn=<AddBackward0>)\n",
      "a7a1 tensor([13.0600], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([14.2700], grad_fn=<AddBackward0>)\n",
      "e1d2 tensor([14.4913], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([14.7124], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([14.6687], grad_fn=<AddBackward0>)\n",
      "b5b6 tensor([15.3316], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([13.7221], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([14.6781], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([14.7124], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      "R . . . . . . .\n",
      ". P . . k . . .\n",
      ". . p . . . . p\n",
      ". . . p . . . .\n",
      ". . . . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "b5b6\n",
      "a7a8 tensor([14.4934], grad_fn=<AddBackward0>)\n",
      "a7h7 tensor([9.5311], grad_fn=<AddBackward0>)\n",
      "a7g7 tensor([13.5462], grad_fn=<AddBackward0>)\n",
      "a7f7 tensor([14.0457], grad_fn=<AddBackward0>)\n",
      "a7e7 tensor([7.5276], grad_fn=<AddBackward0>)\n",
      "a7d7 tensor([6.7559], grad_fn=<AddBackward0>)\n",
      "a7c7 tensor([5.1774], grad_fn=<AddBackward0>)\n",
      "a7b7 tensor([5.9781], grad_fn=<AddBackward0>)\n",
      "a7a6 tensor([11.3951], grad_fn=<AddBackward0>)\n",
      "a7a5 tensor([13.9206], grad_fn=<AddBackward0>)\n",
      "a7a4 tensor([9.9059], grad_fn=<AddBackward0>)\n",
      "a7a3 tensor([15.2561], grad_fn=<AddBackward0>)\n",
      "a7a2 tensor([14.7115], grad_fn=<AddBackward0>)\n",
      "a7a1 tensor([14.0001], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([14.6743], grad_fn=<AddBackward0>)\n",
      "e1d2 tensor([14.8158], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([15.0279], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([14.9380], grad_fn=<AddBackward0>)\n",
      "b6b7 tensor([8.2822], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([14.2929], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([15.0121], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([15.0240], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . p\n",
      ". . p p . . . .\n",
      "R . . . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "a7a3\n",
      "a3a8 tensor([14.0251], grad_fn=<AddBackward0>)\n",
      "a3a7 tensor([14.9396], grad_fn=<AddBackward0>)\n",
      "a3a6 tensor([10.3110], grad_fn=<AddBackward0>)\n",
      "a3a5 tensor([13.2994], grad_fn=<AddBackward0>)\n",
      "a3a4 tensor([10.4568], grad_fn=<AddBackward0>)\n",
      "a3c3 tensor([14.9918], grad_fn=<AddBackward0>)\n",
      "a3b3 tensor([5.7649], grad_fn=<AddBackward0>)\n",
      "a3a2 tensor([14.3646], grad_fn=<AddBackward0>)\n",
      "a3a1 tensor([13.4492], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([9.6367], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([10.6891], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([10.8473], grad_fn=<AddBackward0>)\n",
      "b6b7 tensor([11.4368], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([8.0489], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([10.6103], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([10.6273], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". P . . k . . .\n",
      ". . . . . . . p\n",
      ". . . p . . . .\n",
      ". . R . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "a3c3\n",
      "e1e2 tensor([-3.1982], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([-2.3264], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([-2.9538], grad_fn=<AddBackward0>)\n",
      "b6b7 tensor([-1.1438], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([-3.8426], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([-2.4857], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([-2.7500], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". P . . . . . .\n",
      ". . . . k . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "b6b7\n",
      "e1e2 tensor([-3.5873], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([-2.8093], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([-3.8722], grad_fn=<AddBackward0>)\n",
      "b7b8q tensor([16.0798], grad_fn=<AddBackward0>)\n",
      "b7b8r tensor([8.5875], grad_fn=<AddBackward0>)\n",
      "b7b8b tensor([1.5302], grad_fn=<AddBackward0>)\n",
      "b7b8n tensor([-1.3857], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([-4.7726], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([-3.3190], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([-3.6352], grad_fn=<AddBackward0>)\n",
      ". Q . . . . . .\n",
      ". . . . . k . .\n",
      ". . . . . . . .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "b7b8q\n",
      "b8h8 tensor([15.6441], grad_fn=<AddBackward0>)\n",
      "b8g8 tensor([15.6717], grad_fn=<AddBackward0>)\n",
      "b8f8 tensor([16.0433], grad_fn=<AddBackward0>)\n",
      "b8e8 tensor([15.5724], grad_fn=<AddBackward0>)\n",
      "b8d8 tensor([16.1466], grad_fn=<AddBackward0>)\n",
      "b8c8 tensor([15.4184], grad_fn=<AddBackward0>)\n",
      "b8a8 tensor([16.1586], grad_fn=<AddBackward0>)\n",
      "b8c7 tensor([15.8298], grad_fn=<AddBackward0>)\n",
      "b8b7 tensor([16.1735], grad_fn=<AddBackward0>)\n",
      "b8a7 tensor([16.1544], grad_fn=<AddBackward0>)\n",
      "b8d6 tensor([15.5631], grad_fn=<AddBackward0>)\n",
      "b8b6 tensor([15.6796], grad_fn=<AddBackward0>)\n",
      "b8e5 tensor([15.4923], grad_fn=<AddBackward0>)\n",
      "b8b5 tensor([15.5579], grad_fn=<AddBackward0>)\n",
      "b8f4 tensor([16.0242], grad_fn=<AddBackward0>)\n",
      "b8b4 tensor([15.5765], grad_fn=<AddBackward0>)\n",
      "b8b3 tensor([15.8295], grad_fn=<AddBackward0>)\n",
      "b8b2 tensor([15.9237], grad_fn=<AddBackward0>)\n",
      "b8b1 tensor([15.7625], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([16.0807], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([16.1199], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([16.0986], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([16.0855], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([16.1132], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([16.0469], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". Q . . . . . .\n",
      ". . . . . . k .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "b8b7\n",
      "b7c8 tensor([15.9506], grad_fn=<AddBackward0>)\n",
      "b7b8 tensor([16.2174], grad_fn=<AddBackward0>)\n",
      "b7a8 tensor([16.2287], grad_fn=<AddBackward0>)\n",
      "b7h7 tensor([16.0586], grad_fn=<AddBackward0>)\n",
      "b7g7 tensor([16.1113], grad_fn=<AddBackward0>)\n",
      "b7f7 tensor([16.2039], grad_fn=<AddBackward0>)\n",
      "b7e7 tensor([16.1660], grad_fn=<AddBackward0>)\n",
      "b7d7 tensor([16.0855], grad_fn=<AddBackward0>)\n",
      "b7c7 tensor([16.0949], grad_fn=<AddBackward0>)\n",
      "b7a7 tensor([16.2276], grad_fn=<AddBackward0>)\n",
      "b7c6 tensor([16.0231], grad_fn=<AddBackward0>)\n",
      "b7b6 tensor([16.1144], grad_fn=<AddBackward0>)\n",
      "b7a6 tensor([16.1662], grad_fn=<AddBackward0>)\n",
      "b7d5 tensor([16.1511], grad_fn=<AddBackward0>)\n",
      "b7b5 tensor([16.0076], grad_fn=<AddBackward0>)\n",
      "b7e4 tensor([16.2059], grad_fn=<AddBackward0>)\n",
      "b7b4 tensor([15.9910], grad_fn=<AddBackward0>)\n",
      "b7f3 tensor([16.1127], grad_fn=<AddBackward0>)\n",
      "b7b3 tensor([16.0881], grad_fn=<AddBackward0>)\n",
      "b7g2 tensor([15.1168], grad_fn=<AddBackward0>)\n",
      "b7b2 tensor([16.1254], grad_fn=<AddBackward0>)\n",
      "b7h1 tensor([15.8088], grad_fn=<AddBackward0>)\n",
      "b7b1 tensor([16.1520], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([16.2175], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([16.2310], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([16.2225], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([16.2003], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([16.1690], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([16.2275], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". Q . . . . . .\n",
      ". . . . . . . k\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . . K . .\n",
      "e1f1\n",
      "b7c8 tensor([15.2433], grad_fn=<AddBackward0>)\n",
      "b7b8 tensor([16.1199], grad_fn=<AddBackward0>)\n",
      "b7a8 tensor([16.1441], grad_fn=<AddBackward0>)\n",
      "b7h7 tensor([14.2007], grad_fn=<AddBackward0>)\n",
      "b7g7 tensor([15.1508], grad_fn=<AddBackward0>)\n",
      "b7f7 tensor([16.0202], grad_fn=<AddBackward0>)\n",
      "b7e7 tensor([15.9518], grad_fn=<AddBackward0>)\n",
      "b7d7 tensor([15.6803], grad_fn=<AddBackward0>)\n",
      "b7c7 tensor([15.7495], grad_fn=<AddBackward0>)\n",
      "b7a7 tensor([16.1380], grad_fn=<AddBackward0>)\n",
      "b7c6 tensor([15.0695], grad_fn=<AddBackward0>)\n",
      "b7b6 tensor([15.5702], grad_fn=<AddBackward0>)\n",
      "b7a6 tensor([15.7908], grad_fn=<AddBackward0>)\n",
      "b7d5 tensor([15.8737], grad_fn=<AddBackward0>)\n",
      "b7b5 tensor([15.4318], grad_fn=<AddBackward0>)\n",
      "b7e4 tensor([15.9766], grad_fn=<AddBackward0>)\n",
      "b7b4 tensor([15.4602], grad_fn=<AddBackward0>)\n",
      "b7f3 tensor([15.7686], grad_fn=<AddBackward0>)\n",
      "b7b3 tensor([15.7622], grad_fn=<AddBackward0>)\n",
      "b7g2 tensor([12.3059], grad_fn=<AddBackward0>)\n",
      "b7b2 tensor([15.8887], grad_fn=<AddBackward0>)\n",
      "b7h1 tensor([14.2474], grad_fn=<AddBackward0>)\n",
      "b7b1 tensor([15.7758], grad_fn=<AddBackward0>)\n",
      "f1g2 tensor([16.0935], grad_fn=<AddBackward0>)\n",
      "f1e2 tensor([16.1266], grad_fn=<AddBackward0>)\n",
      "f1g1 tensor([16.0779], grad_fn=<AddBackward0>)\n",
      "f1e1 tensor([16.1735], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([16.0601], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([15.9745], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([16.1371], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". Q . . . . . .\n",
      ". . . . . . k .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "f1e1\n",
      "b7c8 tensor([15.9506], grad_fn=<AddBackward0>)\n",
      "b7b8 tensor([16.2174], grad_fn=<AddBackward0>)\n",
      "b7a8 tensor([16.2287], grad_fn=<AddBackward0>)\n",
      "b7h7 tensor([16.0586], grad_fn=<AddBackward0>)\n",
      "b7g7 tensor([16.1113], grad_fn=<AddBackward0>)\n",
      "b7f7 tensor([16.2039], grad_fn=<AddBackward0>)\n",
      "b7e7 tensor([16.1660], grad_fn=<AddBackward0>)\n",
      "b7d7 tensor([16.0855], grad_fn=<AddBackward0>)\n",
      "b7c7 tensor([16.0949], grad_fn=<AddBackward0>)\n",
      "b7a7 tensor([16.2276], grad_fn=<AddBackward0>)\n",
      "b7c6 tensor([16.0231], grad_fn=<AddBackward0>)\n",
      "b7b6 tensor([16.1144], grad_fn=<AddBackward0>)\n",
      "b7a6 tensor([16.1662], grad_fn=<AddBackward0>)\n",
      "b7d5 tensor([16.1511], grad_fn=<AddBackward0>)\n",
      "b7b5 tensor([16.0076], grad_fn=<AddBackward0>)\n",
      "b7e4 tensor([16.2059], grad_fn=<AddBackward0>)\n",
      "b7b4 tensor([15.9910], grad_fn=<AddBackward0>)\n",
      "b7f3 tensor([16.1127], grad_fn=<AddBackward0>)\n",
      "b7b3 tensor([16.0881], grad_fn=<AddBackward0>)\n",
      "b7g2 tensor([15.1168], grad_fn=<AddBackward0>)\n",
      "b7b2 tensor([16.1254], grad_fn=<AddBackward0>)\n",
      "b7h1 tensor([15.8088], grad_fn=<AddBackward0>)\n",
      "b7b1 tensor([16.1520], grad_fn=<AddBackward0>)\n",
      "e1e2 tensor([16.2175], grad_fn=<AddBackward0>)\n",
      "e1f1 tensor([16.2310], grad_fn=<AddBackward0>)\n",
      "e1d1 tensor([16.2225], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([16.2003], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([16.1690], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([16.2275], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". Q . . . . . .\n",
      ". . . . . . . k\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . . K . .\n",
      "e1f1\n",
      "b7c8 tensor([15.2433], grad_fn=<AddBackward0>)\n",
      "b7b8 tensor([16.1199], grad_fn=<AddBackward0>)\n",
      "b7a8 tensor([16.1441], grad_fn=<AddBackward0>)\n",
      "b7h7 tensor([14.2007], grad_fn=<AddBackward0>)\n",
      "b7g7 tensor([15.1508], grad_fn=<AddBackward0>)\n",
      "b7f7 tensor([16.0202], grad_fn=<AddBackward0>)\n",
      "b7e7 tensor([15.9518], grad_fn=<AddBackward0>)\n",
      "b7d7 tensor([15.6803], grad_fn=<AddBackward0>)\n",
      "b7c7 tensor([15.7495], grad_fn=<AddBackward0>)\n",
      "b7a7 tensor([16.1380], grad_fn=<AddBackward0>)\n",
      "b7c6 tensor([15.0695], grad_fn=<AddBackward0>)\n",
      "b7b6 tensor([15.5702], grad_fn=<AddBackward0>)\n",
      "b7a6 tensor([15.7908], grad_fn=<AddBackward0>)\n",
      "b7d5 tensor([15.8737], grad_fn=<AddBackward0>)\n",
      "b7b5 tensor([15.4318], grad_fn=<AddBackward0>)\n",
      "b7e4 tensor([15.9766], grad_fn=<AddBackward0>)\n",
      "b7b4 tensor([15.4602], grad_fn=<AddBackward0>)\n",
      "b7f3 tensor([15.7686], grad_fn=<AddBackward0>)\n",
      "b7b3 tensor([15.7622], grad_fn=<AddBackward0>)\n",
      "b7g2 tensor([12.3059], grad_fn=<AddBackward0>)\n",
      "b7b2 tensor([15.8887], grad_fn=<AddBackward0>)\n",
      "b7h1 tensor([14.2474], grad_fn=<AddBackward0>)\n",
      "b7b1 tensor([15.7758], grad_fn=<AddBackward0>)\n",
      "f1g2 tensor([16.0935], grad_fn=<AddBackward0>)\n",
      "f1e2 tensor([16.1266], grad_fn=<AddBackward0>)\n",
      "f1g1 tensor([16.0779], grad_fn=<AddBackward0>)\n",
      "f1e1 tensor([16.1735], grad_fn=<AddBackward0>)\n",
      "g3g4 tensor([16.0601], grad_fn=<AddBackward0>)\n",
      "f2f3 tensor([15.9745], grad_fn=<AddBackward0>)\n",
      "f2f4 tensor([16.1371], grad_fn=<AddBackward0>)\n",
      ". . . . . . . .\n",
      ". Q . . . . . .\n",
      ". . . . . . k .\n",
      ". . . . . . . p\n",
      ". . . . . . . .\n",
      ". . p . . . P .\n",
      ". . . . . P . .\n",
      ". . . . K . . .\n",
      "f1e1\n"
     ]
    }
   ],
   "source": [
    "play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ended in a draw vs chess.com 700 elo bot. played like a 100 though     "
   ]
  }
 ]
}